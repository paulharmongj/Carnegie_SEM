---
title: "Carnegie SEM"
author: "Sarah McKnight and Paul Harmon"
output: pdf_document
---

#Introduction:
We are attempting to run an SEM on the Carnegie Classification data to create a new classification system that does not rely on the PCA methodology currently in use. The Carnegie Classifications are currently based on two data-driven PCAs, meaning that loadings can change from year to year.  We hope to create a stable model that better allows for comparisons on a single dimension. This was done using Structural Equation Modeling (SEM).

We attempted to run an SEM on the original, raw data, but it was highly right-skewed, so we changed to using ranked data, as the Carnegie Classification currently uses.  Each of the metrics are ranked based on the minimum method for ties.  These data are much more uniformly distributed than the original data, which were highly skewed in the positive direction. These data included very large values for outlier institutions such as MIT and Harvard, but most of the schools were clustered at smaller values. 

```{r, echo=FALSE}
#read in data
setwd("~/Carnegie-SEM/data")
cc2015 <- read.csv("CC2015data.csv",header = TRUE)

########2015################
cc2015.full <- read.csv("CC2015data.csv", header = TRUE, as.is = TRUE)
#updated file
#cc2015.full <- read.csv("Updated2015.csv", header = TRUE)

cc2015 <- cc2015.full[(cc2015.full$BASIC2015>14&cc2015.full$BASIC2015<18),]
cc2015$BASIC2015 <- factor(cc2015$BASIC2015)

#function for ranking the data
minrank <- function(x){rank(x, ties.method = "min")}

#dataset that we want to use
cc2015Ps<-
  na.omit(cc2015[,c("NAME","BASIC2010","BASIC2015","FACNUM","HUM_RSD","OTHER_RSD","SOCSC_RSD","STEM_RSD","PDNFRSTAFF","S.ER.D","NONS.ER.D")])

#calculate the ranked data
cc2015.r <- data.frame(cc2015Ps[,1:3],sapply(cc2015Ps[,-c(1:3)],minrank)) 
cc2015percap <- cc2015Ps[,c("PDNFRSTAFF","S.ER.D","NONS.ER.D")]/cc2015Ps$FACNUM
colnames(cc2015percap) <- c("PDNFRSTAFF_PC", "S.ER.D_PC", "NONS.ER.D_PC")
cc2015percap.r<-data.frame(sapply(cc2015percap,minrank))
cc2015_new <- cbind(cc2015Ps, cc2015percap)
cc2015_r <- cbind(cc2015.r, cc2015percap.r)
```

```{r data_plots, echo=FALSE}
par(mfrow=c(3,4))
hist(cc2015_r$FACNUM, xlab="FACNUM", main="")
hist(cc2015_r$HUM_RSD, xlab="HUM_RSD", main="")
hist(cc2015_r$OTHER_RSD, xlab="OTHER_RSD", main="")
hist(cc2015_r$SOCSC_RSD, xlab="SOCSC_RSD", main="")
hist(cc2015_r$STEM_RSD, xlab="STEM_RSD", main="")
hist(cc2015_r$PDNFRSTAFF, xlab="PDNFRSTAFF", main="")
hist(cc2015_r$S.ER.D, xlab="S.ER.D", main="")
hist(cc2015_r$NONS.ER.D, xlab="NONS.ER.D", main="")
hist(cc2015_r$PDNFRSTAFF_PC, xlab="PNDRFSTAFF_PC", main="")
hist(cc2015_r$S.ER.D_PC, xlab="S.ER.D_PC", main="")
hist(cc2015_r$NONS.ER.D_PC, xlab="NONS.ER.D_PC", main="")
```

We then attempted a regular SEM with the ranked data. This worked, but only with bootstrapped SE estimates and the fit was terrible (RMSEA = 0.9). Upon further exploration of the data, we realized that certain manifest variables in our data were highly correlated. 

```{r, echo=FALSE}
par(mfrow = c(1,1))
cc2015_matrix2 <- as.matrix(cc2015_r[-c(1:3)])
corrmatrix <- Hmisc::rcorr(cc2015_matrix2)
corrplot::corrplot(corrmatrix$r, order="hclust")
```

So, with this new information in hand, we created a new model, aimed at minimizing RMSEA by modeling correlations. This model fit a lot better than the original model (RMSEA = 0.1) but the overall scores we got out were bimodal.

```{r}
model2 <- '
Aggregate=~HUM_RSD+OTHER_RSD+SOCSC_RSD+STEM_RSD+PDNFRSTAFF+S.ER.D+NONS.ER.D
PerCap=~PDNFRSTAFF_PC+S.ER.D_PC+NONS.ER.D_PC

Overall=~Aggregate+PerCap

S.ER.D~~S.ER.D_PC
NONS.ER.D~~NONS.ER.D_PC
PDNFRSTAFF~~PDNFRSTAFF_PC
PDNFRSTAFF~~S.ER.D
HUM_RSD~~SOCSC_RSD
S.ER.D~~STEM_RSD
PDNFRSTAFF_PC~~S.ER.D_PC
NONS.ER.D~~HUM_RSD
NONS.ER.D~~SOCSC_RSD
'

lavaan_sem_r_cov <- lavaan::sem(model2, data=cc2015_r, std.lv=TRUE, orthogonal=FALSE, se="robust.huber.white")
semPlot::semPaths(lavaan_sem_r_cov)
#lavaan::summary(lavaan_sem_r_cov, fit.measures=TRUE)
CCScores_r_cov <- as.data.frame(lavaan::predict(lavaan_sem_r_cov))
density(CCScores_r_cov$Overall)
range_scores <- max(CCScores_r_cov$Overall) - min(CCScores_r_cov$Overall)
CCScores_r_cov$rate_2015 <- ifelse(CCScores_r_cov$Overall < min(CCScores_r_cov$Overall)+((1/3)*range_scores), 'A', ifelse(CCScores_r_cov$Overall > max(CCScores_r_cov$Overall)-((1/3)*range_scores), 'C', 'B'))
CC_table <- as.data.frame(cbind(cc2015_new$NAME, cc2015_new$BASIC2015, CCScores_r_cov$rate_2015))
colnames(CC_table) <- c("name", "basic2015", "rate2015")
table(cc2015_new$BASIC2015, CC_table$rate2015)
```

Recalling that our original data did not follow a modal distribution, the results seemed strange, and the contingency table showed that we only seemed to able to match up with the highest rating group. With that haing seemingly failed in producing three groups, we switched to Bayesian SEM models.  

#Paul's Bayesian Stuff
An alternative to the traditional SEM model is the Bayesian SEM, which allows for prior distributions to be put on the latent variables. 

In a traditional SEM model, the manifors

These models can be fit using the package "blavaan" (Merkle and Rosseel 2016); however, it is a beta package that is still being tested for validity and stability. 


## Testing with Linear Regression
To better understand the mechanics of the R package Blavaan, we tried fitting a simple regression model to a dataset with which were already familiar. We were able to match the estimates with a linear model using lm(), which is expected. The choice of priors was Normal. 


## A First Model

## Changing Priors
 
## Sensitivity to Priors

##Bayesian SEM - Some Conclusions




#Comparing the SEM model to the Carnegie Classifications
The SEM model and the PCA-based Carnegie model were both used to make plots of aggregate and per-capita traits associated with each institution. Neither plot produces multiple well-separated groups; however, the PCA-based method is slightly more well-separated. 

```{r}
#Generates PCA scores for comparison
PC_ag <- prcomp(cc2015.r[,-c(1,2,3,4)], scale = TRUE)
PC_percap <- prcomp(cc2015percap.r, scale = TRUE)

PC_ag_pred <- predict(PC_ag)[,1]
PC_percap_pred <- predict(PC_percap)[,1]

PC_pred_scale <- apply(as.data.frame(cbind(PC_ag_pred,PC_percap_pred)),2,scale)

#predicts the scores
CCScores_r_cov <- as.data.frame(lavaan::predict(lavaan_sem_r_cov))
CCScores_r_cov_scale <- apply(CCScores_r_cov[,c(1,2)], 2, scale)


###lets see if we can calculate distances with schools
Score_dist <- as.data.frame(cbind(CCScores_r_cov_scale, PC_pred_scale))
rownames(Score_dist) <- cc2015_new$NAME

#recreates the PC-based plot
ggplot(Score_dist) + geom_point(aes(x = PC_ag_pred, y = -PC_percap_pred, color = cc2015_new$BASIC2015)) + ggtitle("Carnegie Classification PC Plot")

ggplot(Score_dist) + geom_point(aes(x = Aggregate, y = PerCap, color = CCScores_r_cov$rate_2015))
```


#Which Schools Move the Most?
The plot below shows which schools move the most relative to their location on the Carnegie classifications. These movements are not systematic; while most of the schools that move the most are near the center, they are not all occurning in one classification level. 

```{r,distances, fig.align = 'center'}
#calculate distances 
get_Distance <- function(x1,x2,y1,y2){
  
 #calculates the euclidean distance between the points  
  dist <- sqrt((x2 - x1)^2 + (y2 - y1)^2)
 distx <- x2 - x1
 disty <- y2 - y1
  #returns distances
  return(list( dist = dist, distx = distx, disty = disty ))
}

Score_dist$Distance <- c()

for (j in 1:nrow(Score_dist)){
  Score_dist$Distance[j] <- get_Distance(x1 = Score_dist[j,"Aggregate"],x2 = Score_dist[j,"PC_ag_pred"],y1 = Score_dist[j,"PerCap"],y2 = -Score_dist[j,"PC_percap_pred"])$dist

  }

#Let's look at distances
sorted <- Score_dist[order(Score_dist$Distance),]
head(sorted,10)
tail(sorted,10)

summary(Score_dist$Distance)

#show biggest movers on Carnegie Classifications Plot
ggplot(Score_dist) + geom_point(aes(x = PC_ag_pred, y = -PC_percap_pred, color = as.factor(floor(Distance)))) + ggtitle("Biggest Movers")

```




#Additional Ways to Visualize These Models
There are two ways that we can visualize these plots. One uses GGplot to create path diagrams in a ggplot-based framework. These are similar to the SemPlot package but may allow for a bit more post processing of the plots. The unfortunate aspect of these plots is that they have to be put together piece by piece - there's no function that directly interfaces with lavaan to get the solution. 
```{r}
#add code to produce a path diagram here
```


An alternative way to look at these models would be to uses the Onyx package, which interfaces with the lavaan code but allows for you to make changes to the path diagrams in a separate window.  These are not great for this kind of context but they are useful for creating pretty-looking path diagrams. Onyx has to be installed from GitHub to work, but other than that it interfaces nicely with lavaan objects. 
```{r}
library(onyxR)
onyx(lavaan_sem_r_cov)
onyx(lavaan_sem_b)
onyx(lavaan_sem_r)
```









